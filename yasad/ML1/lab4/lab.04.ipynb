








<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Jupyter Notebook Viewer</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">
  
  <meta name="robots" content="noindex,nofollow">
  

  <!--NEW RELIC Start Perf Measurement-->
  
  <!--NREND-->

  <!-- Le styles -->
  <script type="text/javascript">
//<![CDATA[
try{if (!window.CloudFlare) {var CloudFlare=[{verbose:0,p:0,byc:0,owlid:"cf",bag2:1,mirage2:0,oracle:0,paths:{cloudflare:"/cdn-cgi/nexp/dok3v=1613a3a185/"},atok:"179c090406de676e83e6d380b5c1bdb9",petok:"b7631a9d05c08ddaa1cfa3b1df5abc65ff9e505f-1462867034-1800",zone:"jupyter.org",rocket:"0",apps:{"ga_key":{"ua":"UA-52617120-5","ga_bs":"2"}},sha2test:0}];!function(a,b){a=document.createElement("script"),b=document.getElementsByTagName("script")[0],a.async=!0,a.src="//ajax.cloudflare.com/cdn-cgi/nexp/dok3v=e982913d31/cloudflare.min.js",b.parentNode.insertBefore(a,b)}()}}catch(e){};
//]]>
</script>
<link href="/static/build/styles.css" rel="stylesheet">

  <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->

  <!-- Le fav and touch icons -->
  <link rel="shortcut icon" href="/static/ico/ipynb_icon_16x16.png">
  <link rel="apple-touch-icon-precomposed" sizes="144x144"
        href="/static/ico/apple-touch-icon-144-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="114x114"
        href="/static/ico/apple-touch-icon-114-precomposed.png">
  <link rel="apple-touch-icon-precomposed" sizes="72x72"
        href="/static/ico/apple-touch-icon-72-precomposed.png">
  <link rel="apple-touch-icon-precomposed"
        href="/static/ico/apple-touch-icon-57-precomposed.png">
  
  

  

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Notebook on nbviewer">
  <meta name="twitter:description" content="Check out this Jupyter notebook!">

  
  <meta name="twitter:domain" content="nbviewer.ipython.org">
  <meta name="twitter:image:src" content="http://ipython.org/ipython-doc/dev/_images/ipynb_icon_128x128.png">

  
    <link href="/static/build/notebook.css" rel="stylesheet">
  

  

  
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript">
    </script>
    <script type="text/javascript">
      init_mathjax = function() {
        if (window.MathJax) {
          // MathJax loaded
          MathJax.Hub.Config({
            TeX: {
              equationNumbers: {
                autoNumber: "AMS",
                useLabelIds: true
              }
            },
            tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
            },
            displayAlign: 'center',
            "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
            }
          });
          MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
      }
      init_mathjax();
    </script>
  

<script type="text/javascript">
/* <![CDATA[ */
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-52617120-5']);
_gaq.push(['_trackPageview']);

(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();

(function(b){(function(a){"__CF"in b&&"DJS"in b.__CF?b.__CF.DJS.push(a):"addEventListener"in b?b.addEventListener("load",a,!1):b.attachEvent("onload",a)})(function(){"FB"in b&&"Event"in FB&&"subscribe"in FB.Event&&(FB.Event.subscribe("edge.create",function(a){_gaq.push(["_trackSocial","facebook","like",a])}),FB.Event.subscribe("edge.remove",function(a){_gaq.push(["_trackSocial","facebook","unlike",a])}),FB.Event.subscribe("message.send",function(a){_gaq.push(["_trackSocial","facebook","send",a])}));"twttr"in b&&"events"in twttr&&"bind"in twttr.events&&twttr.events.bind("tweet",function(a){if(a){var b;if(a.target&&a.target.nodeName=="IFRAME")a:{if(a=a.target.src){a=a.split("#")[0].match(/[^?=&]+=([^&]*)?/g);b=0;for(var c;c=a[b];++b)if(c.indexOf("url")===0){b=unescape(c.split("=")[1]);break a}}b=void 0}_gaq.push(["_trackSocial","twitter","tweet",b])}})})})(window);
/* ]]> */
</script>
</head>

<body class="nbviewer">

  <!-- These are loaded at the top of the body so they are available to
       notebook cells when they are loaded below. -->
  <script src="/static/components/jquery/dist/jquery.min.js"></script>
  <script src="/static/components/requirejs/require.js"></script>
  <script src="/static/components/moment/min/moment.min.js"></script>

<!-- Navbar
================================================== -->
  <nav id="menubar" class="navbar navbar-default navbar-fixed-top" data-spy="affix">
    <div class="container">
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target=".navbar-collapse">
          <span class="sr-only">Toggle navigation</span>
          <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand" href="/">
          <img src="/static/img/nav_logo.svg" width="159"/>
        </a>
      </div>

      <div class="collapse navbar-collapse">
        <ul class="nav navbar-nav navbar-right">
          <li>
            <a class="active" href="http://jupyter.org">JUPYTER</a>
          </li>
          <li>
    <a href="/faq" title="FAQ" >
      
        <span>FAQ</span>
      
    </a>
  </li>

          
  
    
      
        <li>
    <a href="/format/script/urls/dl.dropbox.com/s/tp7i3qh81ft7yew/lab.04.ipynb" title="View as Code" >
      <span class="fa fa- fa-2x menu-icon"></span>
      <span class="menu-text">View as Code</span>
    </a>
  </li>
      
    
  
    
  

  
    <li>
    <a href="#" title="Python 2 Kernel" >
      <span class="fa fa-server fa-2x menu-icon"></span>
      <span class="menu-text">Python 2 Kernel</span>
    </a>
  </li>
  

  

  <li>
    <a href="https://dl.dropbox.com/s/tp7i3qh81ft7yew/lab.04.ipynb" title="Download Notebook" download>
      <span class="fa fa-download fa-2x menu-icon"></span>
      <span class="menu-text">Download Notebook</span>
    </a>
  </li>

        </ul>
      </div><!-- /.navbar-collapse -->
      
      
    </div>
  </nav>

  <div class="container container-main">
    
  
  <div id="notebook">
    <div id="notebook-container">
      
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#1051;&#1072;&#1073;&#1086;&#1088;&#1072;&#1090;&#1086;&#1088;&#1085;&#1072;&#1103;-&#1088;&#1072;&#1073;&#1086;&#1090;&#1072;-4.">&#1051;&#1072;&#1073;&#1086;&#1088;&#1072;&#1090;&#1086;&#1088;&#1085;&#1072;&#1103; &#1088;&#1072;&#1073;&#1086;&#1090;&#1072; 4.<a class="anchor-link" href="#&#1051;&#1072;&#1073;&#1086;&#1088;&#1072;&#1090;&#1086;&#1088;&#1085;&#1072;&#1103;-&#1088;&#1072;&#1073;&#1086;&#1090;&#1072;-4.">&#182;</a></h1><p>Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.</p>
<h3 id="&#1054;&#1094;&#1077;&#1085;&#1080;&#1074;&#1072;&#1085;&#1080;&#1077;-&#1080;-&#1096;&#1090;&#1088;&#1072;&#1092;&#1099;">&#1054;&#1094;&#1077;&#1085;&#1080;&#1074;&#1072;&#1085;&#1080;&#1077; &#1080; &#1096;&#1090;&#1088;&#1072;&#1092;&#1099;<a class="anchor-link" href="#&#1054;&#1094;&#1077;&#1085;&#1080;&#1074;&#1072;&#1085;&#1080;&#1077;-&#1080;-&#1096;&#1090;&#1088;&#1072;&#1092;&#1099;">&#182;</a></h3><p>Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).</p>
<h3 id="&#1055;&#1088;&#1072;&#1074;&#1080;&#1083;&#1072;-&#1089;&#1076;&#1072;&#1095;&#1080;">&#1055;&#1088;&#1072;&#1074;&#1080;&#1083;&#1072; &#1089;&#1076;&#1072;&#1095;&#1080;<a class="anchor-link" href="#&#1055;&#1088;&#1072;&#1074;&#1080;&#1083;&#1072;-&#1089;&#1076;&#1072;&#1095;&#1080;">&#182;</a></h3><p>Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_04.ipynb.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#1047;&#1072;&#1076;&#1072;&#1085;&#1080;&#1077;">&#1047;&#1072;&#1076;&#1072;&#1085;&#1080;&#1077;<a class="anchor-link" href="#&#1047;&#1072;&#1076;&#1072;&#1085;&#1080;&#1077;">&#182;</a></h2><p>В данном задании мы будем работать с подмножеством датасета IMDB Movies Reviews из соревнования <a href="https://www.kaggle.com/c/word2vec-nlp-tutorial/data">Bag of Words Meets Bags of Popcorn</a>. 
<img src="http://i.imgur.com/QZgxFic.png" alt=""></p>
<p>Задача состоит в следующем: по отзыву на фильм необходимо понять является ли он положительным или отрицательным. Это один из примеров задачи анализа тональности текста (<a href="https://en.wikipedia.org/wiki/Sentiment_analysis">sentiment analysis</a>). Пример отзыва из выборки:</p>

<pre><code>This can be one of the most enjoyable movies ever if you don't take it seriously. It is a bit dated and the effects are lame, but it is so enjoyable. There are giant crabs that attack a girl. oh, and the crabs sing Japanese. It is amazingly bad. And the ending, which has been telegraphed throughout the entire film is hideously awesome. Predictable, but seeing the final fight will leave you rolling in your seat. Don't even give this film a chance and you will love it. Susan George is fun to watch and yes, she does appear naked. Her daughter isn't quite worth putting up with, but she does get attacked by giant crabs. They are the size of large cats. This is a 2, but I love it. As a movie, my God, but for entertainment, I give it a 7. Did I mention there are giant crabs?</code></pre>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Загрузите датасет из файла <em>data.tsv</em>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Для оценки качества в данной задаче мы будем использовать отложенную выборку. Разделите все данные на две части: 16000 объектов будет обучающей выборкой и 4000 объектов — тестовой.</p>
<p>Вам будет необходимо учесть следующие особенности разбиения:</p>
<ul>
<li>оно должно быть воспроизводимо</li>
<li>соотношение классов в каждой из частей должно сохраняться (например, при использовании функции <em>train_test_split</em> указать <em>stratify</em>)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Одна из сложностей данной задачи — текстовое представление данных, так как не существует какого-то универсального способа извлечения признаков из текстов. По ходу работы мы получим несколько наборов признаков, которые будем сравнивать между собой.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Для начала попробуем самый простой подход, а именно <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">bag-of-words</a> кодирование данных. С помощью него каждый текст будет представлен в виде вектора, размер которого равен размеру словаря, а на каждой позиции стоит число, сколько раз соответствующее слово встретилось в этом тексте. Кроме того, хорошей практикой является отфильтровывать стоп-слова.</p>
<p>Это представление можно получить используя класс <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer">CountVectorizer</a> из библиотеки sklearn. Одно из удобств данного метода состоит в том, что возвращаемый результат является <a href="http://docs.scipy.org/doc/scipy-0.15.1/reference/sparse.html">sparse</a>-матрицей, так как при таком преобразовании получается достаточно много 0. Более подробно про такие матрицы можно прочитать, например, <a href="http://www.scipy-lectures.org/advanced/scipy_sparse/index.html">здесь</a>.</p>
<p>Примените <em>bag-of-words</em> кодирование данных. Мы рекомендуем обучать здесь и в дальнейшем преобразование на обучающей выборке, после чего применять его к тестовой. Какой размерности стали данные?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>После того как было получено некоторое подходящее представление данных, хочется обучить алгоритмы классификации и сравнить их между собой. Для этого необходимо понять по каким метрикам будут сравниваться алгоритмы. Для начала можно рассмотреть, например, следующе метрики:</p>
<ul>
<li>accuracy: $$ Accuracy = \frac{1}{l}\sum_{i=1}^l[y_i = \hat{y}_i]$$ где $y_i$ — истинный ответ на объекте $x_i$, $\hat{y}_i$ — предсказанный. (мы не рекомендуем переводить <em>accuracy</em> как точность, потому что в русскоязычной литературе точностью называют другую метрику)</li>
<li>точность: $$Precision = \frac{TP}{TP + FP}$$</li>
<li>полнота: $$Recall = \frac{TP}{TP + FN}$$</li>
</ul>
<p>где обозначения <em>TP</em>, <em>FP</em>, <em>FN</em> и <em>TN</em> — элементы матрицы ошибок:</p>
<table>
<thead><tr>
<th></th>
<th>y = 1</th>
<th>y = 0</th>
</tr>
</thead>
<tbody>
<tr>
<td>a(x) = 1</td>
<td>TP</td>
<td>FP</td>
</tr>
<tr>
<td>a(x) = 0</td>
<td>FN</td>
<td>TN</td>
</tr>
</tbody>
</table>
<p>Обратите внимание, что точность и полнота вычисляются относительно фиксированного класса. В sklearn есть удобная функция <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html">classification_report</a>, позволяющая сразу вычислять эти метрики для всех классов.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>(1 балл) Задание 1.</strong></p>
<p>Какие недостатки для данной задачи вы видите у метрики <em>Accuracy</em>?</p>
<p>Обучите логистическую регрессию и случайный лес с 500 деревьев на <em>bag-of-words</em> представлении выборки и измерьте качество на тестовых данных с помощью трех описанных выше метрик. Кроме этого, сравните время обучения алгоритмов. Есть ли существенная разница в качестве алгоритмов? Какой из методов кажется менее применимым в данной задаче и почему?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Посмотрев на указнные метрики, можно понять, что классификаторы неплохо справляются с нулевым классом и похуже — с первым. Скорее всего, это связано с тем, что положительных отзывов почти вдвое меньше. В дальнейшем нас будет интересовать как классификатор справляется именно с положительными отзывами (то есть первым классом). Раньше было замечено, что <em>accuracy</em> не самый подходящий способ измерения качества в данной задаче. Подходят ли оставшиеся две метрики для данной задачи? Эти метрики хороши тем, что могут быть использованы в случае несбалансированнх данных, однако сразу же две метрики оптимизировать не удобно. Поэтому рассмотрим другие подходы к оценке качества.</p>
<p>Зачастую классификатор может возвращать не ответ <em>0</em> или <em>1</em>, а некоторую меру принадлежности заданному классу $b(x)$, которая сравнивается с фиксированным порогом <em>t</em>, и на самом деле классификатор имеет вид $a(x) = [b(x) > t]$. Таким образом, при оценивании качества работы классификатора можно использовать его ответ $b(x)$ и подбирать порог <em>t</em> исходя из некоторых других условий. Кроме того, выбор порога влияет на качество классификации:</p>
<ul>
<li>чем больше $t$, тем выше точность, но ниже полнота,</li>
<li>чем меньше $t$, тем выше полнота, но ниже точность.</li>
</ul>
<h3 id="Precision-Recall-&#1082;&#1088;&#1080;&#1074;&#1072;&#1103;">Precision-Recall &#1082;&#1088;&#1080;&#1074;&#1072;&#1103;<a class="anchor-link" href="#Precision-Recall-&#1082;&#1088;&#1080;&#1074;&#1072;&#1103;">&#182;</a></h3><p>Раз мы умеем варьировать порог классификатора, тем самым меняя качество, интересно каким оно будет при всех возможных различных порогах. Для этого обычно строят следующий график: перебирают все пороги и по оси ОХ откладывают полноту получившегося классификатора, а по оси OY — точность. Таким образом, это дает хорошую наглядную визуализацию качества алгоритма.</p>
<h3 id="ROC-&#1082;&#1088;&#1080;&#1074;&#1072;&#1103;">ROC &#1082;&#1088;&#1080;&#1074;&#1072;&#1103;<a class="anchor-link" href="#ROC-&#1082;&#1088;&#1080;&#1074;&#1072;&#1103;">&#182;</a></h3><p>Еще один из способ визуализации зависимости метрик качества от порога, подходящей в этом случае, является <em>ROC</em>. По осям:</p>
<ul>
<li>OX: $FPR = \frac{FP}{FP + TN}$</li>
<li>OY: $TPR = \frac{TP}{TP + FN}$</li>
</ul>
<p>Кроме того, можно измерять площади под указанными кривыми — <em>auc_pr</em> и <em>auc_roc</em> соответственно.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>(1 балл) Задание 2.</strong></p>
<p>Постройте <em>precision-recall</em> и <em>roc</em> кривые обученных выше классификаторов (каждый тип кривой на отдельном графике), а также вычислите площадь под ними. Для этого удобно воспользоваться функциями <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_curve.html">precision_recall_curve</a>, <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html">roc_curve</a> и <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html#sklearn.metrics.auc">auc</a>. Не забудьте, что в данном случае необходимо использовать метод <em>predict_proba</em> для получения оценки принадлежности к первому классу.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Если мы хотим, чтобы классификатор находил, например, не менее 80% положительных отзывов, то необходимо потребовать, чтобы полнота была не менее 0.8.</p>
<p><strong>(0.5 балла) Задание 3.</strong></p>
<p>Найдите наибольшую точность, которую будет иметь каждый классификатор при полноте не менее 0.8.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>В дальнейшем для экпериментов будем использовать логистическую регрессию. Можно заметить, что по некоторым причинам мы не находили оптимальные параметры для алгоритмов, а работали с параметрами по умолчанию. Чтобы исправить этот недостаток, в дальнейшем используйте кросс-валидацию по 5 блокам для нахождения наилучшего параметра <em>C</em> у логистической регрессии. Для этого удобно использовать класс <a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html">LogisticRegressionCV</a> с оптимизацией <em>roc_auc</em>. Значения параметра <em>C</em> можно перебирать по логарифмической шкале и ограничиться 3-5 значениями.</p>
<p>А теперь вернемся к исходной задаче. На данном этапе решения можно прийти к выводу, что предложенное кодирование текста может быть не самым удачным. Это ведет как к ситуации, что не всякий алгоритм может быть применен в данной задаче по причине слишком большого признакового пространства, а кроме того, даже быстрые алгоритмы при наличии кросс-валидации могут начать работать медленно. Также в данных может быть шум, так как в качестве словаря были взяты все слова, даже те, которые встречались в одном-двух отзывах (например, опечатки). Поэтому кажется что неплохо было бы сократить размерность данных и по возможности избавиться от шума.</p>
<h2 id="&#1054;&#1090;&#1073;&#1086;&#1088;-&#1087;&#1088;&#1080;&#1079;&#1085;&#1072;&#1082;&#1086;&#1074;-&#1080;-&#1091;&#1084;&#1077;&#1085;&#1100;&#1096;&#1077;&#1085;&#1080;&#1077;-&#1088;&#1072;&#1079;&#1084;&#1077;&#1088;&#1085;&#1086;&#1089;&#1090;&#1080;">&#1054;&#1090;&#1073;&#1086;&#1088; &#1087;&#1088;&#1080;&#1079;&#1085;&#1072;&#1082;&#1086;&#1074; &#1080; &#1091;&#1084;&#1077;&#1085;&#1100;&#1096;&#1077;&#1085;&#1080;&#1077; &#1088;&#1072;&#1079;&#1084;&#1077;&#1088;&#1085;&#1086;&#1089;&#1090;&#1080;<a class="anchor-link" href="#&#1054;&#1090;&#1073;&#1086;&#1088;-&#1087;&#1088;&#1080;&#1079;&#1085;&#1072;&#1082;&#1086;&#1074;-&#1080;-&#1091;&#1084;&#1077;&#1085;&#1100;&#1096;&#1077;&#1085;&#1080;&#1077;-&#1088;&#1072;&#1079;&#1084;&#1077;&#1088;&#1085;&#1086;&#1089;&#1090;&#1080;">&#182;</a></h2><h3 id="&#1055;&#1086;-&#1095;&#1072;&#1089;&#1090;&#1086;&#1090;&#1077;">&#1055;&#1086; &#1095;&#1072;&#1089;&#1090;&#1086;&#1090;&#1077;<a class="anchor-link" href="#&#1055;&#1086;-&#1095;&#1072;&#1089;&#1090;&#1086;&#1090;&#1077;">&#182;</a></h3><p>Попробуем сформировать выборку, в которой будут находиться только самые "важные" признаки, то есть в данном случае слова. Например, это можно сделать оставив топ слов по частоте. Кажется, что вхождение наиболее частых слов в отзыве, например <em>good</em>, <em>bad</em> и т.д. являются вполне неплохими показателями.</p>
<h3 id="&#1057;-&#1087;&#1086;&#1084;&#1086;&#1097;&#1100;&#1102;-&#1084;&#1072;&#1096;&#1080;&#1085;&#1085;&#1086;&#1075;&#1086;-&#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1103;">&#1057; &#1087;&#1086;&#1084;&#1086;&#1097;&#1100;&#1102; &#1084;&#1072;&#1096;&#1080;&#1085;&#1085;&#1086;&#1075;&#1086; &#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1103;<a class="anchor-link" href="#&#1057;-&#1087;&#1086;&#1084;&#1086;&#1097;&#1100;&#1102;-&#1084;&#1072;&#1096;&#1080;&#1085;&#1085;&#1086;&#1075;&#1086;-&#1086;&#1073;&#1091;&#1095;&#1077;&#1085;&#1080;&#1103;">&#182;</a></h3><p>Другой подход — воспользоваться имеющимся машинным обучением — обученным на всех признаках случайным лесом. Одним из свойств случайного леса является оценка важности признаков. Таким образом, можно выбрать топ слов, важных как признаки для задачи классификации.</p>
<h3 id="Hashing-trick">Hashing trick<a class="anchor-link" href="#Hashing-trick">&#182;</a></h3><p>Какие еще могут быть способы работы с такого рода данными? По факту слова в текстах — это некоторое очень разреженное представление (как мы убедились выше). Подходом, отличным от двух вышеперечисленных, является <a href="https://en.wikipedia.org/wiki/Feature_hashing">хэширование</a> или hashing trick: каждому слову сопоставляется некоторый хэш, после чего делается, например, bag-of-words. Из-за коллизий можно обработать не встречавшихся ранее слов. Этот подход реализован в классе <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html">HashingVectorizer</a>. Кроме того, если выставить параметр <em>non_negative=True</em>, то можно интерпретировать полученные значения как некоторые "частоты".</p>
<p>Можно заметить, что два последних подхода можно применять не обязательно к текстовым данным.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>(1 балл) Задание 4.</strong></p>
<p>Сформируйте три новые выборки, где каждый объект будет иметь 15000 признаков, следующим образом:</p>
<ul>
<li>топ самых частотных слов</li>
<li>топ наиболее "важных" слов с помощью случайного леса</li>
<li>с помощью хэширования</li>
</ul>
<p>(и не забывайте фильтровать стоп-слова).</p>
<p>На четырех выборках (<em>bag-of-words</em> и трех новых) постройте <em>roc</em>-кривые, вычислив площадь под ними. Что вы можете сказать о качестве этих подходов к сокращению размерности?</p>
<p>Выведите топ20 самых важных слов от случайного леса и сравните их с топ20 наиболее частотных. Много ли общих слов?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Таким образом, удалось сократить размерность более чем в три раза без сильной потери в качестве. Но даже 15000 признаков — это достаточно много. Допустим, мы хотим уменьшить размерность до 2000 признаков, однако можно заметить, что даже три предыдущие способа давали небольшое ухудшение в качестве.</p>
<h3 id="PCA">PCA<a class="anchor-link" href="#PCA">&#182;</a></h3><p>Одним из способов сокращения размерности является <a href="https://en.wikipedia.org/wiki/Principal_component_analysis">PCA</a> (метод главных компонент). Это преобразование позволяет получить вес каждого признака в компоненте. Например, если применить его к bag-of-words, можно найти наиболее важные слова, влияющие на данную компоненту. Для работы с большими разреженными матрицами в sklearn рекомендуется использовать <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">TruncatedSVD</a>. Обратите внимание, что обучение этого преобразования может работать около 3-5 минут.</p>
<p><strong>(1 балл) Задание 5.</strong></p>
<p>Попробуйте сократить размерность до 2000 двумя способами:</p>
<ul>
<li>наилучшим из трех предыдущих</li>
<li>для выборки со всеми признаками обучите <em>PCA</em>-преобразование </li>
</ul>
<p>Постройте новый график качества. Какой из двух подходов работает лучше?</p>
<p>Для первых трех компонент преобразования найдите топ30 наиболее важных слов. Можете ли вы охарактеризовать как-то каждую из этих групп?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#1050;&#1072;&#1082;&#1080;&#1077;-&#1077;&#1097;&#1077;-&#1084;&#1086;&#1075;&#1091;&#1090;-&#1073;&#1099;&#1090;&#1100;-&#1089;&#1087;&#1086;&#1089;&#1086;&#1073;&#1099;-&#1086;&#1073;&#1088;&#1072;&#1073;&#1086;&#1090;&#1082;&#1080;-&#1090;&#1077;&#1082;&#1089;&#1090;&#1086;&#1074;&#1099;&#1093;-&#1076;&#1072;&#1085;&#1085;&#1099;&#1093;?">&#1050;&#1072;&#1082;&#1080;&#1077; &#1077;&#1097;&#1077; &#1084;&#1086;&#1075;&#1091;&#1090; &#1073;&#1099;&#1090;&#1100; &#1089;&#1087;&#1086;&#1089;&#1086;&#1073;&#1099; &#1086;&#1073;&#1088;&#1072;&#1073;&#1086;&#1090;&#1082;&#1080; &#1090;&#1077;&#1082;&#1089;&#1090;&#1086;&#1074;&#1099;&#1093; &#1076;&#1072;&#1085;&#1085;&#1099;&#1093;?<a class="anchor-link" href="#&#1050;&#1072;&#1082;&#1080;&#1077;-&#1077;&#1097;&#1077;-&#1084;&#1086;&#1075;&#1091;&#1090;-&#1073;&#1099;&#1090;&#1100;-&#1089;&#1087;&#1086;&#1089;&#1086;&#1073;&#1099;-&#1086;&#1073;&#1088;&#1072;&#1073;&#1086;&#1090;&#1082;&#1080;-&#1090;&#1077;&#1082;&#1089;&#1090;&#1086;&#1074;&#1099;&#1093;-&#1076;&#1072;&#1085;&#1085;&#1099;&#1093;?">&#182;</a></h3><p>Как можно заметить, подход с мешком слов весьма наивен, так как не позволяет учесть информацию в скольки отзывах встречалось слово (чтобы избавиться от очень редких слов, например). В этом случае может помочь, например, <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html">tf-idf кодирование</a>.</p>
<p>Другой недостаток описанного в задании подхода — брать абсолютные частоты. У некоторых слов они могут быть очень большими, в то же время у других — низкими. Чтобы "сгладить" разницу между ними, можно их отлогарифмировать, т.е. применить преобразование $x \to log(x + 1)$ (так как при bag-of-words кодировании могут встречаться 0).</p>
<p>Неплохое руководство можно найти в разделе <a href="http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction">извлечения признаков</a> из документации sklearn.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Stacking">Stacking<a class="anchor-link" href="#Stacking">&#182;</a></h2><p>Итак, сейчас имеется несколько разных способов охарактеризовать исходный датасет:</p>
<ul>
<li>bag-of-words</li>
<li>bag-of-words для 15000 наиболее частотных слов</li>
<li>bag-of-words для 15000 наиболее важных признаков</li>
<li>признаки, полученные в результате хэширования</li>
<li>применение PCA для bag-of-words</li>
</ul>
<p>Во второй лабораторной вы пробовали линейно смешивать несколько классификаторов для улучшения итогового качества, перебирая коэффициенты смешивания по сетке. А вообще говоря, подбор оптимальных линейных коэффициентов — это задача обучения линейной модели, которую мы уже давно изучаем в курсе. Так что давайте попробуем смешивать базовые алгоритмы, подбирая коэффициенты с помощью обученной поверх их предсказаний линейной мета-модели. В этом случае схема обучения будет выглядеть следующим образом:</p>
<p><img src="http://cse-wiki.unl.edu/wiki/images/5/54/Combining_classifiers_overview.png" alt=""></p>
<p>Такой подход, когда предсказания одних алгоритмов подаются на вход другому алгоритму, называется stacking. Плюс такого подхода будет заключаться в том, что новое признаковое описание будет небольшим, поэтому можно легко использовать любые известные вам методы.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>(1.5 балла) Задание 6.</strong></p>
<ul>
<li>Объясните, будет ли происходить переобучение, если обучать базовые алгоритмы и мета-модель на одной и той же выборке? Для простоты можете представить, что в качестве базового алгоритма используется 1-NN.</li>
<li>Для начала разделите каждую обучающую выборку на две части и на одной из частей обучите базовые классификаторы (в данном случае — логистическую регрессию). Сделайте разделение таким образом, чтобы для обучения мета-алгоритма осталось 4000 объектов.</li>
<li>Сделайте предсказание этих классификаторов на оставшейся части</li>
<li>На ответах классификаторов обучите новый классификатор, который и будет являться мета-алгоритмом. В качестве мета-классификатора рассматрите SVM с линейным ядром, логистическую регрессию и случайный лес со 100 деревьями. </li>
</ul>
<p>Для всех ли мета-классификаторов этот подход дал прирост в качестве?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#1055;&#1086;&#1076;&#1073;&#1086;&#1088;-&#1075;&#1080;&#1087;&#1077;&#1088;&#1087;&#1072;&#1088;&#1072;&#1084;&#1077;&#1090;&#1088;&#1086;&#1074;">&#1055;&#1086;&#1076;&#1073;&#1086;&#1088; &#1075;&#1080;&#1087;&#1077;&#1088;&#1087;&#1072;&#1088;&#1072;&#1084;&#1077;&#1090;&#1088;&#1086;&#1074;<a class="anchor-link" href="#&#1055;&#1086;&#1076;&#1073;&#1086;&#1088;-&#1075;&#1080;&#1087;&#1077;&#1088;&#1087;&#1072;&#1088;&#1072;&#1084;&#1077;&#1090;&#1088;&#1086;&#1074;">&#182;</a></h2><p>Вы уже знаете, что для подбора гиперпараметров есть способ перебора по сетке. Обычно перебор некоторых значений гиперпараметров ведется по логарифмической шкале, так как это позволяет быстрее определить какого порядка должен быть параметр, и в то же время значительно уменьшить время поиска. Последний нюанс бывает особо критичен, т.к. для каждого фиксированного набора параметров происходит обучение алгритма и оценка качества.</p>
<p>Однако такой подход к нахождению гиперпараметров является не единственно возможным. Рассмотрим более конкретно в чем может заключаться недостаток предыдущего подхода. Допустим, вам нужно подобрать 2 гиперпараметра, для каждого из которых есть сетка из 4 возможных значений. То есть всего 16 итераций обучения по сетке. Допустим также, что для оценки качества используется 5-fold CV. В итоге имеем 80 переобучений алгоритма, что уже немало. А если, например, рассмотреть случаный лес, где гиперпараметрами могут являться критерий ветвления, максимальная глубина деревьев, минимальное число объектов в листьях, максимальное число признаков, количество листьев и так далее, может получиться экспоненциально большое число переобучений, что займёт очень много времени. Для того чтобы как-то ускорить процесс и в то же время найти близкие к оптимальным значения используют случайный поиск по сетке. В этом случае для каждого гиперпараметра задается распределение, из которого он выбирается. И так как каждый раз значение каждого гиперпараметра выбирается случайно, это позволяет находить оптимальные значения быстрее.</p>
<p>Если сравнить случайный поиск с обычным, то это можно проиллюстрировать, например, следующим образом:</p>
<p><img src="http://blog.kaggle.com/wp-content/uploads/2015/07/scikitlearn8.jpeg" alt=""></p>
<p>Более подробно можно прочитать тут:</p>
<ul>
<li>теоретический анализ случайного поиска <a href="http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf">Random Search for Hyper-Parameter Optimization</a></li>
<li>кратко и с юмором <a href="https://medium.com/rants-on-machine-learning/smarter-parameter-sweeps-or-why-grid-search-is-plain-stupid-c17d97a0e881#.pkwq17od8">Smarter Parameter Sweeps (or Why Grid Search Is Plain Stupid)</a></li>
</ul>
<p>В sklearn случайный поиск по сетке реализован в классе <a href="http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html">RandomizedSearchCV</a>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Давайте попробуем сравнить описанные подходы на практике. А именно, посмотрим, как ведет себя обычный и случайный поиск по сетке при одинаковом бюджете (то есть числе итераций). Попробуем найти аптимальные гиперпараметры для мета-классификатора выше: SVM с линейным ядром. В данном случае нам будет интересны найти значения у двух параметров: <em>C</em> и количество итераций <em>max_iter</em>. Для обоих гиперпараметров возьмите логарифмическую шкалу, для <em>C</em> от 0.1 до 100, для <em>max_iter</em> от 1000 до 10000 (см. функцию <a href="http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.logspace.html">logspace</a>). В качестве оптимизируемой метрики качества выберем <em>AUC-ROC</em>.</p>
<p><strong>(2 балла) Задание 7.</strong></p>
<ul>
<li><p>Для простого поиска по сетке подготовьте 5 сеток гиперпараметров, так чтобы каждый у каждого гиперпараметра перебиралось 2, 3, 4, 5 и 6 значений в соответствующей сетке. Таким образом у вас получится 5 запусков поиска параметров с бюджетом 4, 9, 16, 25, 36.</p>
</li>
<li><p>Для случайного поиска сделайте 5 запусков поиска гиперпараметров с числом итераций (бюджетом) 4, 9, 16, 25, 36.</p>
</li>
<li><p>Для каждого из запусков алгоритма подбора гиперпараметров (одного — обычной и 5 для случайной) вычислите наилучшее достигнутое качество для каждого бюджета. После чего постройте график, где по оси OX будет отложен бюджет, а по оси OY — наилучшее качество.</p>
</li>
</ul>
<p>Что вы можете сказать о получившемся графике? Посмотрите на наилучшие параметры, которые у вас получились. Можно ли сказать, что какой-то из параметров больше влияет на результат? Можно ли сделать вывод, что случайный поиск проигрывает? Или наоборот? Зависит ли ответ на предыдущий вопрос от размера бюджета или удачной инициализации?</p>
<p>Обратите внимание, что данная часть лабораторной работы может работать долго. Поэтому рекомендуем обратить внимание на параметр <em>n_jobs</em> поиска по сетке (есть у обоих классов).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="&#1050;&#1072;&#1083;&#1080;&#1073;&#1088;&#1086;&#1074;&#1082;&#1072;-&#1082;&#1083;&#1072;&#1089;&#1089;&#1080;&#1092;&#1080;&#1082;&#1072;&#1090;&#1086;&#1088;&#1072;">&#1050;&#1072;&#1083;&#1080;&#1073;&#1088;&#1086;&#1074;&#1082;&#1072; &#1082;&#1083;&#1072;&#1089;&#1089;&#1080;&#1092;&#1080;&#1082;&#1072;&#1090;&#1086;&#1088;&#1072;<a class="anchor-link" href="#&#1050;&#1072;&#1083;&#1080;&#1073;&#1088;&#1086;&#1074;&#1082;&#1072;-&#1082;&#1083;&#1072;&#1089;&#1089;&#1080;&#1092;&#1080;&#1082;&#1072;&#1090;&#1086;&#1088;&#1072;">&#182;</a></h2><p>Для измерения качества классификации помимо описанных ранее метрик может использоваться, например, <em>logloss</em>.</p>
<p>В бинарном случае эта метрика записывается как $$logloss = -\dfrac{1}{N}\sum_{i=1}^N (y_i\log{p_i} + (1-y_i)\log{(1 - p_i)})$$</p>
<p>В отличии от <em>AUC-ROC</em>, для этой метрики необходимо, чтобы классификатор умел предсказывать вероятность принадлежности к классу, а не "степени принадлежности классу 1" в неопределенной шкале. Приведем пример. Вероятностная шкала может быть нужна, если вы хотите оценить количество денег, которые в среднем принесёт пользователь, кликнув на баннер. Для этого необходимо умножить количество денег, которые вы получаете за клик на баннер, на вероятность клика пользователя, которую предсказывает модель.</p>
<p>К сожалению, на практике часто получается так, что либо классификатор не обладает желаемым свойством (например, SVM без специальных настроек), либо метод <em>predict_proba</em> возвращает некорректную вероятность (например, случайный лес возвращает среднее арифметическое вероятностей от каждого дерева, которое не обязано являться корректной вероятностью, подробнее <a href="http://people.dsv.su.se/~henke/papers/bostrom08b.pdf">здесь</a>).</p>
<p>В этом случае возможны несколько подходов:</p>
<ul>
<li>заменить классификатор на тот, который умеет предсказывать вероятности</li>
<li>воспользоваться калибровкой ответов.</li>
</ul>
<p>Первый случай не всегда подходит, поэтому остановимся на втором. По умолчанию SVM может вычислять отступ от данного объекта до разделяющей гиперплоскости, а не возвращать вероятности. После чего можно обучить преобразование, которое бы искажало бы возвращаемое значение в вероятность  — это и называется калибровкой. Есть несколько известных методов для этого:</p>
<ul>
<li>калибровка Платта;</li>
<li>изотоническая регрессия.</li>
</ul>
<p>Обратите внимание, что преобразование необходимо обучать на отложенной выборке (то есть классификатор и калибровка должны производиться на разных подмножествах данных), иначе можно переобучиться. Калибровку можно применять к любым классификаторам (где это разумно и необходимо), особенно к тем, которые не оптимизируют log-loss явно.</p>
<p>Для калибровки классификатора в sklearn возможны два подхода:</p>
<ul>
<li>взять уже обученный классификатор и откалибровать его на отложенной выборке</li>
<li>откалибровать по кросс-валидации: калибровочному классификатору передается вся обучающая выборка, которая внутри разбивается на обучающую и калибровочную, после чего происходит усреднение вероятностей по фолдам.</li>
</ul>
<p>Подробнее об этом можно прочитать в <a href="http://scikit-learn.org/stable/modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV">документации</a>. Также <a href="https://jmetzen.github.io/2015-04-14/calibration.html">здесь</a> узнать подробности о калибровке в sklearn от автора.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>(2 балла) Задание 8.</strong></p>
<p>Рассмотрим SVM из предыдущего пункта. Примените оба описанных выше подхода для калибровки Платта и изотонической регрессии.</p>
<ul>
<li>Для каждого из подходов постройте график, на котором будут изображены <a href="http://scikit-learn.org/stable/modules/generated/sklearn.calibration.calibration_curve.html">калибровочные кривые</a>: идеальная, исходного классификатора, а также для каждого из методов на обучающей выборке. Эта кривая строится путем упорядочения всех объектов по предсказанному значению, которые разбиваются на бины. По оси OX откладывается среднее предсказанное значение вероятности по бину, а по OY — доля положительных примеров. В случае идеальных вероятностей это будет прямая.</li>
<li>Посчитайте <em>logloss</em> на тестовой выборке для исходного и классификатора после калибровки.</li>
<li>Дает ли калибровка прирост качества?</li>
<li>Какой из способов калибровки в данном случае работает лучше?</li>
<li>Какой из подходов (калибровка на отложенной выборке или по кросс-валидации) дает более хороший результат?</li>
<li>Почему калибровка практически не должна повлиять на <em>AUC-ROC</em>? </li>
</ul>
<p>Обратите внимание, что по умолчанию SVM не реализует метод <em>predict_proba</em>. Поэтому для него можно воспользоваться методом <em>decision_function</em>, который вернет значение отступа. После этого отмасштабируйте полученные отступы в интервал [0, 1], применив сигмоиду или линейное преобразование.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython2"><pre><span></span> 
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Замечание напоследок. Выше написано, что SVM по умолчанию не возвращает вероятности. Если же заглянуть в документацию <a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">SVC</a>, то можно найти параметр <em>probability</em>. Если установить его равным <em>True</em>, то у такого классификатора можно вызвать метод <em>predict_proba</em> и получить оценки вероятностей. Внутри библиотеки реализована калибровка Платта, и с классификатором проделывается примерно тоже самое, что было описано выше. Использование этого параметра замедляет процесс обучения, зато позволяет сразу же использовать данный классификатор для оценивания вероятностей. Обратите внимание, что у класса <a href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html">LinearSVC</a> такой опции нет.</p>

</div>
</div>
</div>
    </div>
  </div>

  </div>


  
    <footer class="footer hidden-print">
      <div class="container">
        <div class="col-md-4">
          <p>
            This website does not host notebooks, it only renders notebooks
            available on other websites.
          </p>
        </div>

        <div class="col-md-4">
          <p>
            Delivered by <a href="http://www.fastly.com/">Fastly</a>,
            Rendered by <a href="https://developer.rackspace.com/?nbviewer=awesome">Rackspace</a>
          </p>
          <p>
            nbviewer GitHub <a href="https://github.com/jupyter/nbviewer">repository</a>.
          </p>
        </div>

        <div class="col-md-4">
          
  
            
              <p>
                nbviewer version:
                <a href="https://github.com/jupyter/nbviewer/commit/0bf9258c078c4b09eec914172d10524e644cdb4e">
                  0bf9258
                </a>
              </p>
            
          
  
  <p>
    nbconvert version: <a href="https://github.com/jupyter/nbconvert/releases/tag/4.2.0">
      4.2.0
    </a>
  </p>
  

          
  
  
  <p>
    Rendered
    <span class='date' data-date='Tue, 10 May 2016 07:54:14 UTC' title='Tue, 10 May 2016 07:54:14 UTC'>(Tue, 10 May 2016 07:54:14 UTC)</span>
  </p>
  

        </div>
      </div>
    </footer>
  

  <script src="/static/components/bootstrap/js/bootstrap.min.js"></script>
  <script src="/static/components/headroom.js/dist/headroom.min.js"></script>
  <script src="/static/components/headroom.js/dist/jQuery.headroom.min.js"></script>

  
  
  <script>
    $(function(){ $("#menubar").headroom({
      tolerance: 5,
      offset: 205,
      classes: {
        initial: "animated",
        pinned: "slideInDown",
        unpinned: "slideOutUp"
      }
    })});
  </script>


  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-38683231-2', 'auto');
    ga('send', 'pageview');
  </script>
  <script>
    require({
        paths: {
          moment: "/static/components/moment/min/moment.min.js"
        }
      }, ["moment"], function(moment){
      var date = $("footer .date"),
        m = moment(new Date(date.data('date'))),
        update = function(){ date.text(m.fromNow()); };
      setInterval(update, 61*1000);
      update();
      var w = $(window).scroll(function(event){
        $("body").toggleClass("scrolled", w.scrollTop() > 0);
      });
    });
  </script>
  <!--NEW RELIC Stop Perf Measurement-->
  
  <!--NEW RELIC End-->
</body>
</html>