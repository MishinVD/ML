{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_list(X, y, clf, print_score=True):\n",
    "    predictions = list()\n",
    "    scores = list()\n",
    "    for i, tree in enumerate(clf.estimators_):\n",
    "        predictions.append(tree.predict_proba(X))\n",
    "        rf_prediction = mean(predictions, axis=0)\n",
    "        scores.append(log_loss(y, rf_prediction))\n",
    "    if print_score:\n",
    "        print 'Last score', scores[-1]\n",
    "    return scores\n",
    "\n",
    "def plot_auc_graph(clf, X_train, X_test, y_train, y_test, prefix, print_train=True):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_aucs = get_auc_list(X_train, y_train, clf, print_train)\n",
    "    test_aucs = get_auc_list(X_test, y_test, clf, True)\n",
    "    if print_train:\n",
    "        plot(train_aucs, label=prefix + ' train set')\n",
    "    plot(test_aucs, label=prefix + ' test set')\n",
    "    xlabel('n_estimators')\n",
    "    ylabel('log_loss')\n",
    "    legend(loc=1)\n",
    "    \n",
    "def plot_features_random_forest(clf):\n",
    "    importances = clf.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # Print the feature ranking\n",
    "#     print(\"Feature ranking:\")\n",
    "\n",
    "    # for f in range(X_train.shape[1]):\n",
    "    #     print(\\\"%d. feature %d (%f)\\\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X_train.shape[1]), importances[indices])\n",
    "    plt.xticks(range(X_train.shape[1]), indices)\n",
    "    plt.xlim([-1, X_train.shape[1]])\n",
    "    plt.show()\n",
    "    \n",
    "def plot_quality(grid_searcher, param_name):\n",
    "    means = []\n",
    "    stds = []\n",
    "    for elem in grid_searcher.grid_scores_:\n",
    "        means.append(mean(elem.cv_validation_scores))\n",
    "        stds.append(sqrt(var(elem.cv_validation_scores)))\n",
    "    means = array(means)\n",
    "    stds = array(stds)\n",
    "    \n",
    "    params = grid_searcher.param_grid\n",
    "    \n",
    "    figure(figsize=(8, 6))\n",
    "    plot(params[param_name], means)\n",
    "    fill_between(params[param_name], \\\n",
    "                 means + stds, means - stds, alpha = 0.3, facecolor='blue')\n",
    "    xlabel(param_name)\n",
    "    ylabel('LOG LOSS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пояснение модели\n",
    "Традиционно данные были разбиты на train, test, validation. Потом были всяческие жалкие попытки обучить приличный случайный лес. После 100500 раза были опробованы 5 линейных моделей, которые по отдельности давали результат значительно хуже RandomForest, по после усреднения были сравнимы качество было сравнимо с RandomForest. После такого было решено обучить какое-то кол-во моделей, а в качестве ответа предоставить среднее значение.\n",
    "\n",
    "Ну и ниже идет просто обучение различных моделей, порой они очень похожи, порой они бердовые и не объяснимы.\n",
    "\n",
    "А вообще, похоже на какую-то очень плохую модель, которая выстрелила при удачных random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING. БЫДЛОКОД detected\n",
    "<img src=\"http://cs622927.vk.me/v622927463/3239e/idTHUIWcuZk.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.linear_model import LogisticRegression as SAG\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier as ETC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm  import SVC \n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция котороая разбивает train на части, потом предсказывает одну часть по осатльным. По итогу получим получаем дополнительный признак - выход конкретной модели. Эта идеи была высказана на семинаре 12 апреля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "def getCVOutFromModel(inputClf, X, y, colName='Prediction', preTrans=None, nFolds=3, randomState=0, needScores=False):\n",
    "    kf_total = KFold(X.shape[0], n_folds=nFolds, shuffle=True, random_state=randomState)\n",
    "    \n",
    "    yPred = pd.DataFrame()\n",
    "    scores = []\n",
    "    for train_index, test_index in kf_total:\n",
    "        clf = inputClf;\n",
    "        matrXFit = preTrans.transform(X.iloc[train_index, :]) if preTrans else X.iloc[train_index, :]\n",
    "        yFit = y[train_index]\n",
    "        matrXTest = preTrans.transform(X.iloc[test_index, :]) if preTrans else X.iloc[test_index, :]\n",
    "        yTest = y[test_index]\n",
    "\n",
    "        clf.fit(matrXFit, yFit)\n",
    "\n",
    "        pred = clf.predict_proba(matrXTest)\n",
    "        scores.append(log_loss(yTest, pred))\n",
    "        yPred = yPred.append(pd.DataFrame(pred[:,1], index=X_train.iloc[test_index, :].index))\n",
    "    \n",
    "    yPred.columns = [colName]\n",
    "    \n",
    "    if needScores:\n",
    "        return yPred, scores\n",
    "    else:\n",
    "        return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# глобальные переменные.\n",
    "GLOBAL_RANDOM_CV = 75441\n",
    "GLOBAL_TRAIN_TEST_VALID_SPLIT = 643423\n",
    "GLOBAL_RND_SELECT_MODEL = 5432543\n",
    "GLOBAL_RND_MODEL = 6534245\n",
    "\n",
    "GLOBAL_NFOLD = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = pd.read_csv('X.train.csv')\n",
    "Xtest = pd.read_csv('X.test.csv')\n",
    "\n",
    "ytrain = pd.read_csv('y.train.csv')['label']\n",
    "\n",
    "Xfull = pd.concat([Xtrain, Xtest], axis=0)\n",
    "# есть мнение что признак 'V48' имеет значение 0 и NA, причем NA не дает никакой информации\n",
    "Xfull.drop('V48', axis=1, inplace=True)\n",
    "Xfull.fillna(-9999, inplace=True)\n",
    "\n",
    "ytrain = ytrain.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4099, 1329) (1366, 1329)\n",
      "(4099, 1330) (1366, 1330)\n"
     ]
    }
   ],
   "source": [
    "X_train = Xfull.iloc[:ytrain.shape[0], :]\n",
    "X_sub = Xfull.iloc[ytrain.shape[0]:, :]\n",
    "print X_train.shape, X_sub.shape\n",
    "print Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут стоит отметить, что в ходе исследований разбиение было 60/20/20 (train/valid/test). И поэтому качества моделей на выборках test и valid были весьма адекватными. После выбора итоговой модели разбиение превратилось в 95/2.5/2.5 (train/valid/test), чтобы увеличить обучающую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "10\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, ytrain, test_size=0.05,\n",
    "                                                    random_state=GLOBAL_TRAIN_TEST_VALID_SPLIT)\n",
    "X_test, X_valid, y_test, y_valid  = train_test_split(X_test, y_test, test_size=0.5,\n",
    "                                                     random_state=GLOBAL_TRAIN_TEST_VALID_SPLIT)\n",
    "print sum(y_train)\n",
    "print sum(y_valid)\n",
    "print sum(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "featureX_train - тут храним выходы функции getCVOutFromModel от разных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureX_train = pd.DataFrame(index=X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель 1-4\n",
    "Случайные леса, только выбираем самые важные признаки.\n",
    "1. RandomForest 'важные' признаки выбираются RandomForest\n",
    "2. RandomForest 'важные' признаки выбираются ExtraTreesClassifier\n",
    "3. ExtraTreesClassifier 'важные' признаки выбираются RandomForest\n",
    "4. ExtraTreesClassifier 'важные' признаки выбираются ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selectModel_1 = SelectFromModel(RFC(n_estimators=800, criterion='entropy',\n",
    "                                    random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "selectModel_1.fit(X_train, y_train);\n",
    "\n",
    "selectModel_2 = SelectFromModel(ETC(n_estimators=800, criterion='entropy',\n",
    "                                    random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "selectModel_2.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = RFC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL)\n",
    "model2 = ETC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 45s, sys: 2 s, total: 29min 47s\n",
      "Wall time: 29min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y1, sc1 = getCVOutFromModel(model1, X_train, y_train, preTrans=selectModel_1,\n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y2, sc2 = getCVOutFromModel(model1, X_train, y_train, preTrans=selectModel_2,\n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y3, sc3 = getCVOutFromModel(model2, X_train, y_train, preTrans=selectModel_1,\n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y4, sc4 = getCVOutFromModel(model2, X_train, y_train, preTrans=selectModel_2,\n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19717266403563266, 0.22017340207599317, 0.25580726248706726, 0.26050159533880207, 0.14680525936048611, 0.20076601628624624, 0.28331507881307111, 0.1679456809126991, 0.20677161417424614, 0.17673370091404106, 0.18350044033067728, 0.20619545182908061, 0.22844683971373056]\n",
      "[0.20330133419378019, 0.21667248277697884, 0.24622645943114208, 0.2579091628091526, 0.14927124214564752, 0.20063516546614285, 0.2830740942954979, 0.16571819528913861, 0.20133735029115951, 0.17802554096777257, 0.1803895237475259, 0.20984969102472759, 0.2192210665592591]\n",
      "[0.19272566686914705, 0.22432738601201563, 0.25430867864453888, 0.25302738000609132, 0.14090683098618975, 0.18140123197459265, 0.28224204896234711, 0.16896131850319324, 0.21430854322291903, 0.17394927676489449, 0.1854672685606702, 0.20842394816517612, 0.21368083332425189]\n",
      "[0.20778235628848635, 0.21327754465441898, 0.23990636812559757, 0.25174074436072186, 0.14800609118892238, 0.19602780049735191, 0.28025368831588643, 0.16541739899167579, 0.20278371686689811, 0.1808938115869537, 0.18004773018846601, 0.20883725685860369, 0.2173483596930357]\n"
     ]
    }
   ],
   "source": [
    "print sc1\n",
    "print sc2\n",
    "print sc3\n",
    "print sc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureX_train['y1'] = y1\n",
    "featureX_train['y2'] = y2\n",
    "featureX_train['y3'] = y3\n",
    "featureX_train['y4'] = y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 220)\n",
      "(3894, 220)\n"
     ]
    }
   ],
   "source": [
    "print selectModel_1.transform(X_valid).shape\n",
    "print selectModel_1.transform(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = RFC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL) #selectModel_1\n",
    "m2 = RFC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL) #selectModel_2\n",
    "m3 = ETC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL) #selectModel_1\n",
    "m4 = ETC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL) #selectModel_2\n",
    "\n",
    "m1.fit(selectModel_1.transform(X_train), y_train)\n",
    "m2.fit(selectModel_2.transform(X_train), y_train)\n",
    "m3.fit(selectModel_1.transform(X_train), y_train)\n",
    "m4.fit(selectModel_2.transform(X_train), y_train)\n",
    "\n",
    "yv1 = m1.predict_proba(selectModel_1.transform(X_valid))\n",
    "yv2 = m2.predict_proba(selectModel_2.transform(X_valid))\n",
    "yv3 = m3.predict_proba(selectModel_1.transform(X_valid))\n",
    "yv4 = m4.predict_proba(selectModel_2.transform(X_valid))\n",
    "\n",
    "yt1 = m1.predict_proba(selectModel_1.transform(X_test))\n",
    "yt2 = m2.predict_proba(selectModel_2.transform(X_test))\n",
    "yt3 = m3.predict_proba(selectModel_1.transform(X_test))\n",
    "yt4 = m4.predict_proba(selectModel_2.transform(X_test))\n",
    "\n",
    "featureX_valid = pd.DataFrame(index=X_valid.index)\n",
    "featureX_valid['y1'] = yv1[:, 1]\n",
    "featureX_valid['y2'] = yv2[:, 1]\n",
    "featureX_valid['y3'] = yv3[:, 1]\n",
    "featureX_valid['y4'] = yv4[:, 1]\n",
    "\n",
    "featureX_test = pd.DataFrame(index=X_test.index)\n",
    "featureX_test['y1'] = yt1[:, 1]\n",
    "featureX_test['y2'] = yt2[:, 1]\n",
    "featureX_test['y3'] = yt3[:, 1]\n",
    "featureX_test['y4'] = yt4[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys1 = m1.predict_proba(selectModel_1.transform(X_sub))\n",
    "ys2 = m2.predict_proba(selectModel_2.transform(X_sub))\n",
    "ys3 = m3.predict_proba(selectModel_1.transform(X_sub))\n",
    "ys4 = m4.predict_proba(selectModel_2.transform(X_sub))\n",
    "\n",
    "featureX_sub = pd.DataFrame(index=X_sub.index)\n",
    "featureX_sub['y1'] = ys1[:, 1]\n",
    "featureX_sub['y2'] = ys2[:, 1]\n",
    "featureX_sub['y3'] = ys3[:, 1]\n",
    "featureX_sub['y4'] = ys4[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAENCAYAAAAmBe1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7526f6c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = m1.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in m1.estimators_],\n",
    "         axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices])\n",
    "plt.xticks(arange(1, len(indices), 25), X_valid.columns[selectModel_1.get_support()][indices])\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.231460512334\n",
      "0.259135779932\n",
      "0.206860742967\n"
     ]
    }
   ],
   "source": [
    "print log_loss(y_valid, np.array([1-featureX_valid.mean(axis=1), featureX_valid.mean(axis=1)]).T)\n",
    "print log_loss(y_test, np.array([1-featureX_test.mean(axis=1), featureX_test.mean(axis=1)]).T)\n",
    "print log_loss(y_train, np.array([1-featureX_train.mean(axis=1), featureX_train.mean(axis=1)]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models 5-8\n",
    "Модели обучались только на не категориальных признаках. Параметры были подобраны GridSearchCV несколько днями ранеее\n",
    "1. SVC\n",
    "2. KNN\n",
    "3. LogisticRegression L1 Regularization\n",
    "4. LogisticRegression L2 Regularization\n",
    "5. SGDClassifier - not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Meta = pd.read_csv('MetaData.csv', index_col=0)\n",
    "notCategoryFeatures = Meta.index[Meta.Column_Type != 'Category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preProcSTD = StandardScaler()\n",
    "preProcSTD.fit(X_train[notCategoryFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmModel = SVC(probability=True, random_state=GLOBAL_RND_MODEL, C=0.351)\n",
    "knnModel = KNeighborsClassifier(weights='distance', n_neighbors=150)\n",
    "logL1Model = LogisticRegression(penalty='l1', C=0.15, random_state=GLOBAL_RND_MODEL)\n",
    "logL2Model = LogisticRegression(penalty='l2', C=0.15, random_state=GLOBAL_RND_MODEL)\n",
    "sgdModel = SGDClassifier(random_state=GLOBAL_RND_MODEL, loss='log', alpha=0.0288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23887330248238087, 0.22791041595479963, 0.29284393234707418, 0.28918129345379295, 0.18556978485098538, 0.24732806532684554, 0.32320455761198275, 0.19505769785796895, 0.22977203484394707, 0.22155411755910909, 0.21436049659242462, 0.2617632712882792, 0.26261253949269714]\n",
      "[0.22838146457365496, 0.34120263537504303, 0.31107586382128516, 0.30689659210902209, 0.17807865662928818, 0.24377832287958312, 0.31864007846400888, 0.17378232449077033, 0.23490016060708505, 0.22773720797335606, 0.19916477524314535, 0.23526879195617445, 0.29164993012937979]\n",
      "[0.21688689084525076, 0.22287872162502084, 0.2689851684553875, 0.28642723317186863, 0.15706697272177722, 0.22464634336451036, 0.31004949623962241, 0.16772297507946668, 0.21233486769365562, 0.18643605169025246, 0.19022337526356664, 0.22971949921478485, 0.24143816937908913]\n",
      "[0.23793093285479761, 0.2255514731443328, 0.27530773315966423, 0.28939174782875532, 0.15794937401706283, 0.23988561870615907, 0.31282911862735413, 0.17420637718047746, 0.20997817978802344, 0.18986939416862036, 0.19768285215054821, 0.23647267290588486, 0.23976813414441539]\n",
      "[0.49173996821357963, 0.50100565237484218, 0.66151903696888026, 0.81986825149963849, 0.34475157368546794, 0.64871591150447339, 0.72577308059937129, 0.28520099541793481, 0.43878885620009184, 0.32680075543687515, 0.38794830955629045, 0.48259653863464713, 0.49835066387698918]\n",
      "CPU times: user 1min 23s, sys: 34.7 s, total: 1min 57s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y5, sc5 = getCVOutFromModel(svmModel, X_train[notCategoryFeatures], y_train, preTrans=preProcSTD,\n",
    "                            nFolds=GLOBAL_NFOLD,\n",
    "                            randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y6, sc6 = getCVOutFromModel(knnModel, X_train[notCategoryFeatures], y_train, preTrans=preProcSTD,\n",
    "                            nFolds=GLOBAL_NFOLD,\n",
    "                            randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y7, sc7 = getCVOutFromModel(logL1Model, X_train[notCategoryFeatures], y_train, preTrans=preProcSTD,\n",
    "                            nFolds=GLOBAL_NFOLD,\n",
    "                            randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y8, sc8 = getCVOutFromModel(logL2Model, X_train[notCategoryFeatures], y_train, preTrans=preProcSTD,\n",
    "                            nFolds=GLOBAL_NFOLD,\n",
    "                            randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "y9, sc9 = getCVOutFromModel(sgdModel, X_train[notCategoryFeatures], y_train, preTrans=preProcSTD,\n",
    "                            nFolds=GLOBAL_NFOLD,\n",
    "                            randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "print sc5\n",
    "print sc6\n",
    "print sc7\n",
    "print sc8\n",
    "print sc9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureX_train['y5'] = y5\n",
    "featureX_train['y6'] = y6\n",
    "featureX_train['y7'] = y7\n",
    "featureX_train['y8'] = y8\n",
    "# featureX_train['y9'] = y9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svmModel = SVC(probability=True, random_state=GLOBAL_RND_MODEL, C=0.351)\n",
    "knnModel = KNeighborsClassifier(weights='distance', n_neighbors=150)\n",
    "logL1Model = LogisticRegression(penalty='l1', C=0.15, random_state=GLOBAL_RND_MODEL)\n",
    "logL2Model = LogisticRegression(penalty='l2', C=0.15, random_state=GLOBAL_RND_MODEL)\n",
    "# sgdModel = SGDClassifier(random_state=514, loss='log', alpha=0.0288)\n",
    "\n",
    "svmModel.fit(preProcSTD.transform(X_train[notCategoryFeatures]), y_train)\n",
    "knnModel.fit(preProcSTD.transform(X_train[notCategoryFeatures]), y_train)\n",
    "logL1Model.fit(preProcSTD.transform(X_train[notCategoryFeatures]), y_train)\n",
    "logL2Model.fit(preProcSTD.transform(X_train[notCategoryFeatures]), y_train)\n",
    "\n",
    "yv5 = svmModel.predict_proba(preProcSTD.transform(X_valid[notCategoryFeatures]))\n",
    "yv6 = knnModel.predict_proba(preProcSTD.transform(X_valid[notCategoryFeatures]))\n",
    "yv7 = logL1Model.predict_proba(preProcSTD.transform(X_valid[notCategoryFeatures]))\n",
    "yv8 = logL2Model.predict_proba(preProcSTD.transform(X_valid[notCategoryFeatures]))\n",
    "\n",
    "yt5 = svmModel.predict_proba(preProcSTD.transform(X_test[notCategoryFeatures]))\n",
    "yt6 = knnModel.predict_proba(preProcSTD.transform(X_test[notCategoryFeatures]))\n",
    "yt7 = logL1Model.predict_proba(preProcSTD.transform(X_test[notCategoryFeatures]))\n",
    "yt8 = logL2Model.predict_proba(preProcSTD.transform(X_test[notCategoryFeatures]))\n",
    "\n",
    "# featureX_valid = pd.DataFrame(index=X_valid.index)\n",
    "featureX_valid['y5'] = yv5[:, 1]\n",
    "featureX_valid['y6'] = yv6[:, 1]\n",
    "featureX_valid['y7'] = yv7[:, 1]\n",
    "featureX_valid['y8'] = yv8[:, 1]\n",
    "\n",
    "# featureX_test = pd.DataFrame(index=X_test.index)\n",
    "featureX_test['y5'] = yt5[:, 1]\n",
    "featureX_test['y6'] = yt6[:, 1]\n",
    "featureX_test['y7'] = yt7[:, 1]\n",
    "featureX_test['y8'] = yt8[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys5 = svmModel.predict_proba(preProcSTD.transform(X_sub[notCategoryFeatures]))\n",
    "ys6 = knnModel.predict_proba(preProcSTD.transform(X_sub[notCategoryFeatures]))\n",
    "ys7 = logL1Model.predict_proba(preProcSTD.transform(X_sub[notCategoryFeatures]))\n",
    "ys8 = logL2Model.predict_proba(preProcSTD.transform(X_sub[notCategoryFeatures]))\n",
    "\n",
    "# featureX_valid = pd.DataFrame(index=X_valid.index)\n",
    "featureX_sub['y5'] = ys5[:, 1]\n",
    "featureX_sub['y6'] = ys6[:, 1]\n",
    "featureX_sub['y7'] = ys7[:, 1]\n",
    "featureX_sub['y8'] = ys8[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# featureX_test.drop('y_', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.239217751047\n",
      "0.263669399234\n",
      "0.212848406214\n"
     ]
    }
   ],
   "source": [
    "print log_loss(y_valid, np.array([1-featureX_valid.mean(axis=1), featureX_valid.mean(axis=1)]).T)\n",
    "print log_loss(y_test, np.array([1-featureX_test.mean(axis=1), featureX_test.mean(axis=1)]).T)\n",
    "print log_loss(y_train, np.array([1-featureX_train.mean(axis=1), featureX_train.mean(axis=1)]).T)\n",
    "# 0.207193396576\n",
    "# 0.218516409148\n",
    "# 0.21697000027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первая попытка обобщить полученные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_ = pd.concat([X_train, featureX_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = SelectFromModel(RFC(n_estimators=800, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "s.fit(X_train_, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1907478665913625, 0.271313451732629, 0.18344890965601293, 0.24198346133960713, 0.18690494553749776, 0.18528560678865202, 0.21630595105514619]\n"
     ]
    }
   ],
   "source": [
    "y_, sc_ = getCVOutFromModel(RFC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X_train_, y_train, preTrans=s,\n",
    "                            nFolds=7, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "print sc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=2500, n_jobs=1,\n",
       "            oob_score=False, random_state=6534245, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RFC(n_estimators=2500, criterion='entropy', random_state=GLOBAL_RND_MODEL)\n",
    "rf.fit(s.transform(X_train_), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.253204238198\n",
      "0.238914461842\n"
     ]
    }
   ],
   "source": [
    "X_test_ = pd.concat([X_test, featureX_test], axis=1)\n",
    "print log_loss(y_test, rf.predict_proba(s.transform(X_test_)))\n",
    "\n",
    "X_valid_ = pd.concat([X_valid, featureX_valid], axis=1)\n",
    "print log_loss(y_valid, rf.predict_proba(s.transform(X_valid_)))\n",
    "\n",
    "# mean forests\n",
    "# 0.218516409148\n",
    "# 0.207193396576\n",
    "\n",
    "# RFC 25000\n",
    "# 0.217318170197\n",
    "# 0.205574898974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAENCAYAAAASfCxYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nME7uZmZmBePkbmZmVjBO7mZmZgXz/wFfYqZI744P6AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe751f9d2d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "         axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices])\n",
    "plt.xticks(arange(1, len(indices), 25), X_valid_.columns[s.get_support()][indices])\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обертка для getCVOutFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCVModel_fit_transform(inputClf, X, y,\n",
    "                              validData, testData,\n",
    "                              colName='Prediction', preTrans=None, nFolds=3, randomState=0,\n",
    "                              needScores=False):\n",
    "    clf = inputClf\n",
    "    if needScores:\n",
    "        y_, sc_ = getCVOutFromModel(clf, X, y, colName=colName, preTrans=preTrans,\n",
    "                                nFolds=nFolds, randomState=randomState, needScores=needScores)\n",
    "    else:\n",
    "        y_ = getCVOutFromModel(clf, X, y, colName=colName, preTrans=preTrans,\n",
    "                                nFolds=nFolds, randomState=randomState, needScores=needScores)\n",
    "\n",
    "    Xfit_ = preTrans.transform(X) if preTrans else X\n",
    "    clf.fit(Xfit_, y)\n",
    "\n",
    "    Xvalid_ = preTrans.transform(validData) if preTrans else validData\n",
    "    Xtest_ = preTrans.transform(testData) if preTrans else testData\n",
    "    \n",
    "    yv_ = clf.predict_proba(Xvalid_)\n",
    "    yt_ = clf.predict_proba(Xtest_)\n",
    "    \n",
    "    if needScores:\n",
    "        return y_, yv_, yt_, clf, sc_\n",
    "    else:\n",
    "        return y_, yv_, yt_, clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoder\n",
    "9-я модель Обучаем RandomForest на данных после OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=1,\n",
       "            oob_score=False, random_state=5432543, verbose=0,\n",
       "            warm_start=False),\n",
       "        prefit=False, threshold=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "allCategoryFeatures = Meta[Meta.Column_Type == 'Category'].index\n",
    "allCategoryFeatures = allCategoryFeatures.drop('V48')\n",
    "\n",
    "X_trainOne = X_train.copy()\n",
    "X_validOne = X_valid.copy()\n",
    "X_testOne = X_test.copy()\n",
    "X_subOne = X_sub.copy()\n",
    "\n",
    "\n",
    "X_trainOne['type'] = 'train'\n",
    "X_validOne['type'] = 'valid'\n",
    "X_testOne['type'] = 'test'\n",
    "X_subOne['type'] = 'sub'\n",
    "\n",
    "X_FULL = pd.concat([X_trainOne, X_validOne, X_testOne, X_subOne], axis=0)\n",
    "toOnehot = np.abs(X_FULL[allCategoryFeatures].as_matrix())\n",
    "onehotX = OneHotEncoder(sparse=False).fit_transform(toOnehot)\n",
    "\n",
    "X_onehot = pd.concat([X_FULL, pd.DataFrame(onehotX, index=X_FULL.index)], axis=1)\n",
    "\n",
    "X_trainOne = X_onehot[X_onehot.type == 'train'].drop('type', axis=1)\n",
    "X_validOne = X_onehot[X_onehot.type == 'valid'].drop('type', axis=1)\n",
    "X_testOne = X_onehot[X_onehot.type == 'test'].drop('type', axis=1)\n",
    "X_subOne = X_onehot[X_onehot.type == 'sub'].drop('type', axis=1)\n",
    "\n",
    "\n",
    "clf_onehot = RFC(n_estimators=600, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL)\n",
    "sfm_rf_onehot = SelectFromModel(clf_onehot)\n",
    "sfm_rf_onehot.fit(X_trainOne, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20401263543424983, 0.21891730913904392, 0.25053464916747209, 0.25705241694509889, 0.1497458451458204, 0.20634664791160937, 0.28804347460796376, 0.16988438507065459, 0.20787219242461799, 0.18303084733782685, 0.18394564027323235, 0.20834599719257729, 0.23172787323910973]\n",
      "0.241222020365\n",
      "0.260326840329\n"
     ]
    }
   ],
   "source": [
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=1600, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_trainOne,\n",
    "                            y=y_train,\n",
    "                            validData=X_validOne,\n",
    "                            testData=X_testOne,\n",
    "                            preTrans=sfm_rf_onehot, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureX_train['OneHot'] = y_\n",
    "featureX_test['OneHot'] = yt_[:, 1]\n",
    "featureX_valid['OneHot'] = yv_[:, 1]\n",
    "featureX_sub['OneHot'] = clf.predict_proba(sfm_rf_onehot.transform( X_subOne))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "10-я модель. Заменяем категориальные признаки счетчиками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(X, y, col, kfold=5, random_state=512):\n",
    "    dt = pd.DataFrame(index=X.index)\n",
    "    dt['y'] = y\n",
    "    dt[col] = X[col]\n",
    "    \n",
    "    R = pd.DataFrame(columns=[col])\n",
    "    \n",
    "    if(kfold > 1):\n",
    "        kf = KFold(n=dt.shape[0], n_folds=kfold, shuffle=True, random_state=random_state)\n",
    "    \n",
    "        for train_index, test_index in kf:\n",
    "            tr_index = dt.index[train_index]\n",
    "            ts_index = dt.index[test_index]\n",
    "            gp = dt.ix[tr_index,:].groupby(col)\n",
    "            R = pd.concat([X.ix[ts_index, col].replace(gp.mean()['y'].to_dict()), R], axis=0)\n",
    "        \n",
    "        return R[0]\n",
    "    \n",
    "def fit(X, y, col):\n",
    "    dt = X.copy()\n",
    "    dt['y'] = y\n",
    "    gp = dt.groupby(col)\n",
    "    return gp.mean()['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mostImpotence = X_valid.columns[selectModel_1.get_support()][indices]\n",
    "# mostImpotence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainCount = X_train.copy()\n",
    "X_validCount = X_valid.copy()\n",
    "X_testCount = X_test.copy()\n",
    "X_subCount = X_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 42s, sys: 1min 15s, total: 7min 57s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "A = Meta.Column_Type #[mostImpotence]\n",
    "mostImpCategoryFeatures = A[A == 'Category'].index\n",
    "mostImpCategoryFeatures = mostImpCategoryFeatures.drop('V48')\n",
    "\n",
    "for col in mostImpCategoryFeatures:\n",
    "    X_trainCount[col + 'trans'] = transform(X_trainCount, y_train, col=col,\n",
    "                                            kfold=GLOBAL_NFOLD, random_state=GLOBAL_RANDOM_CV)\n",
    "\n",
    "for col in mostImpCategoryFeatures:\n",
    "    g = fit(X_trainCount, y_train, col=col)\n",
    "    X_validCount[col + 'trans'] = X_validCount[col].replace(g)\n",
    "    X_testCount[col + 'trans'] = X_testCount[col].replace(g)\n",
    "    X_subCount[col + 'trans'] = X_subCount[col].replace(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=600, n_jobs=1,\n",
       "            oob_score=False, random_state=5432543, verbose=0,\n",
       "            warm_start=False),\n",
       "        prefit=False, threshold=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm_rf_count = SelectFromModel(RFC(n_estimators=600, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sfm_rf_count.fit(X_trainCount, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20342261190467487, 0.21556472906284033, 0.24671144321497215, 0.26343570831755658, 0.14620140448498836, 0.20260329741129618, 0.28400498109408262, 0.15875017745964662, 0.20435201763399771, 0.18127071594055014, 0.17570684454014396, 0.20520438209021136, 0.23539243657444112]\n",
      "0.236159597121\n",
      "0.276549691171\n"
     ]
    }
   ],
   "source": [
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=1600, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_trainCount,\n",
    "                            y=y_train,\n",
    "                            validData=X_validCount,\n",
    "                            testData=X_testCount,\n",
    "                            preTrans=sfm_rf_count, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "# 0.18625053974\n",
    "# 0.237523654944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 2509)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validCount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureX_train['Count'] = y_\n",
    "featureX_test['Count'] = yt_[:, 1]\n",
    "featureX_valid['Count'] = yv_[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureX_sub['Count'] = clf.predict_proba(sfm_rf_count.transform(X_subCount))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выкидываем некоторые признаки\n",
    "11-я модель. Выкидываем признаки, которые с низкой дисперсией. Потом обучаем RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nzvFeatures = [\"V3\", \"V14\", \"V18\", \"V20\", \"V26\", \"V27\", \"V45\", \"V46\", \"V47\", \"V49\",\n",
    "               \"V50\", \"V51\", \"V56\", \"V58\", \"V59\", \"V60\", \"V61\", \"V62\", \"V65\", \"V66\", \n",
    "                \"V73\", \"V90\", \"V94\", \"V96\", \"V98\", \"V153\", \"V196\", \"V202\", \"V347\", \"V357\",\n",
    "               \"V380\", \"V411\", \"V439\", \"V458\", \"V482\", \"V483\", \"V504\", \"V519\", \"V566\",\n",
    "                 \"V581\", \"V583\", \"V601\", \"V602\", \"V603\", \"V604\", \"V607\", \"V637\", \"V667\",\n",
    "               \"V670\", \"V671\", \"V675\", \"V698\", \"V723\", \"V773\", \"V781\", \"V801\", \"V817\", \n",
    "                 \"V834\", \"V840\", \"V841\", \"V849\", \"V887\" , \"V920\", \"V921\", \"V953\", \"V986\", \n",
    "               \"V987\", \"V988\", \"V1012\", \"V1016\", \"V1042\", \"V1047\", \"V1069\", \"V1070\", \n",
    "                 \"V1071\", \"V1114\", \"V1170\", \"V1208\", \"V1209\", \"V1226\", \"V1245\", \"V1271\", \"V1294\", \"V1329\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_trainDROP = X_train.drop(nzvFeatures, axis=1)\n",
    "X_validDROP = X_valid.drop(nzvFeatures, axis=1)\n",
    "X_testDROP = X_test.drop(nzvFeatures, axis=1)\n",
    "X_subDROP  = X_sub.drop(nzvFeatures, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19721749655950163, 0.22110920964237379, 0.25633386778820844, 0.26254187171878651, 0.1469910800756366, 0.20018147394490693, 0.28448373889825967, 0.16808106179697752, 0.20674986621678521, 0.17528545573116472, 0.18409925929986345, 0.20781524789831077, 0.23063093742691315]\n",
      "0.237943660771\n",
      "0.254434547276\n",
      "CPU times: user 15min 27s, sys: 376 ms, total: 15min 28s\n",
      "Wall time: 15min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sfm_rf_DROP = SelectFromModel(RFC(n_estimators=700, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sfm_rf_DROP.fit(X_trainDROP, y_train)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=2600, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_trainDROP,\n",
    "                            y=y_train,\n",
    "                            validData=X_validDROP,\n",
    "                            testData=X_testDROP,\n",
    "                            preTrans=sfm_rf_DROP, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "featureX_train['Drop'] = y_\n",
    "featureX_test['Drop'] = yt_[:, 1]\n",
    "featureX_valid['Drop'] = yv_[:, 1]\n",
    "featureX_sub['Drop'] = clf.predict_proba(sfm_rf_DROP.transform(X_subDROP))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High cor features\n",
    "12-я модель. Выкидываем один из признаков, который сильно коррелирует с другим. Потом обучаем RandomForest. Файл corr.up.8.csv был получен с помощью функции <a href=\"http://topepo.github.io/caret/preprocess.html\">findLinearCombos</a>. Аналог в python не нашел, писать стало лень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highCorFeatures = pd.read_csv('corr.up.8.csv').highlyCorDescr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_trainDROP = X_train.drop(highCorFeatures, axis=1)\n",
    "X_validDROP = X_valid.drop(highCorFeatures, axis=1)\n",
    "X_testDROP = X_test.drop(highCorFeatures, axis=1)\n",
    "X_subDROP  = X_sub.drop(highCorFeatures, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20159816634233613, 0.22064471012021566, 0.25168631742230618, 0.25974816283347701, 0.14791012192370728, 0.19711985261328976, 0.27915127506287152, 0.16667504679250442, 0.20615335535428012, 0.1809789229173305, 0.17966669827661272, 0.20843379677212648, 0.22638061719516583]\n",
      "0.238324317566\n",
      "0.259653918799\n",
      "CPU times: user 7min 28s, sys: 108 ms, total: 7min 28s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sfm_rf_DROP = SelectFromModel(RFC(n_estimators=500, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sfm_rf_DROP.fit(X_trainDROP, y_train)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_trainDROP,\n",
    "                            y=y_train,\n",
    "                            validData=X_validDROP,\n",
    "                            testData=X_testDROP,\n",
    "                            preTrans=sfm_rf_DROP, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "featureX_train['Drop_HIGH_Cor'] = y_\n",
    "featureX_test['Drop_HIGH_Cor'] = yt_[:, 1]\n",
    "featureX_valid['Drop_HIGH_Cor'] = yv_[:, 1]\n",
    "featureX_sub['Drop_HIGH_Cor'] = clf.predict_proba(sfm_rf_DROP.transform(X_subDROP))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Склеим рядом стоящие аллеи\n",
    "Не имеет рационального смысла, пробовал вдруг зажгёт. И получим еще несколько моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_concat = X_train.copy()\n",
    "X_test_concat = X_test.copy()\n",
    "X_valid_concat = X_valid.copy()\n",
    "X_sub_concat = X_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "v1 = 330\n",
    "v2 = 331\n",
    "v3 = 332\n",
    "v4 = 333\n",
    "\n",
    "for i in range(0, 470):\n",
    "    X_train_concat['VV' + str(v1+v2)] = X_train.iloc[:, [v1, v2]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    X_test_concat['VV' + str(v1+v2)]  = X_test.iloc[:, [v1, v2]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    X_valid_concat['VV' + str(v1+v2)] = X_valid.iloc[:, [v1, v2]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    X_sub_concat['VV' + str(v1+v2)]   = X_sub.iloc[:, [v1, v2]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    v1 += 2\n",
    "    v2 += 2    \n",
    "    \n",
    "v1 = 330\n",
    "v2 = 331\n",
    "v3 = 332\n",
    "v4 = 333\n",
    "\n",
    "for i in range(0, 330):\n",
    "    X_train_concat['VVV' + str(v1+v2+v3)] = X_train.iloc[:, [v1, v2, v3]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    X_test_concat['VVV' + str(v1+v2+v3)]  = X_test.iloc[:, [v1, v2, v3]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    X_valid_concat['VVV' + str(v1+v2+v3)] = X_valid.iloc[:, [v1, v2, v3]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    X_sub_concat['VVV' + str(v1+v2+v3)]   = X_sub.iloc[:, [v1, v2, v3]].astype(str).sum(axis=1).apply(lambda x: x.replace('.', '#'))\n",
    "    v1 += 3\n",
    "    v2 += 3\n",
    "    v3 += 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummy_col(X, col):\n",
    "    X = pd.concat([X, pd.get_dummies(X[col]).rename(columns=lambda x: col + str(x))], axis=1)\n",
    "#     X.drop(col, axis=1, inplace=True)\n",
    "    return X.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for col in X_train_concat.columns[-1049:]:\n",
    "#     X_train_concat = dummy_col(X_train_concat, col)\n",
    "#     X_valid_concat = dummy_col(X_valid_concat, col)\n",
    "#     X_test_concat  = dummy_col(X_test_concat, col)\n",
    "#     X_sub_concat   = dummy_col(X_sub_concat, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_concat['type'] = 'train'\n",
    "X_valid_concat['type'] = 'valid'\n",
    "X_test_concat['type'] = 'test'\n",
    "X_sub_concat['type'] = 'sub'\n",
    "\n",
    "X_FULL_concat = pd.concat([X_train_concat, X_valid_concat, X_test_concat, X_sub_concat], axis=0)\n",
    "for col in X_FULL_concat.columns[-1049:]:\n",
    "    X_FULL_concat = dummy_col(X_FULL_concat, col)\n",
    "    \n",
    "X_train_concat = X_FULL_concat[X_FULL_concat.typetrain == 1].drop(['typesub', 'typevalid', 'typetest', 'typetrain'], axis=1)\n",
    "X_valid_concat = X_FULL_concat[X_FULL_concat.typevalid == 1].drop(['typesub', 'typevalid', 'typetest', 'typetrain'], axis=1)\n",
    "X_test_concat = X_FULL_concat[X_FULL_concat.typetest == 1].drop(['typesub', 'typevalid', 'typetest', 'typetrain'], axis=1)\n",
    "X_sub_concat = X_FULL_concat[X_FULL_concat.typesub == 1].drop(['typesub', 'typevalid', 'typetest', 'typetrain'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_train_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train_concat.shape\n",
    "print X_valid_concat.shape\n",
    "print X_test_concat.shape\n",
    "print X_sub_concat.shape\n",
    "print X_train.shape\n",
    "print X_valid.shape\n",
    "print X_test.shape\n",
    "print X_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfm_rf_concat = SelectFromModel(RFC(n_estimators=650,\n",
    "                                    criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL),\n",
    "                               threshold='7*mean')\n",
    "sfm_rf_concat.fit(X_train_concat, y_train)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_train_concat,\n",
    "                            y=y_train,\n",
    "                            validData=X_valid_concat,\n",
    "                            testData=X_test_concat,\n",
    "                            preTrans=sfm_rf_concat, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "featureX_train['ConcatGen7_mean'] = y_\n",
    "featureX_test['ConcatGen7_mean'] = yt_[:, 1]\n",
    "featureX_valid['ConcatGen7_mean'] = yv_[:, 1]\n",
    "featureX_sub['ConcatGen7_mean'] = clf.predict_proba(sfm_rf_concat.transform(X_sub_concat))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfm_rf_concat = SelectFromModel(RFC(n_estimators=650,\n",
    "                                    criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL),\n",
    "                               threshold='5*mean')\n",
    "sfm_rf_concat.fit(X_train_concat, y_train)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_train_concat,\n",
    "                            y=y_train,\n",
    "                            validData=X_valid_concat,\n",
    "                            testData=X_test_concat,\n",
    "                            preTrans=sfm_rf_concat, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "featureX_train['ConcatGen5_mean'] = y_\n",
    "featureX_test['ConcatGen5_mean'] = yt_[:, 1]\n",
    "featureX_valid['ConcatGen5_mean'] = yv_[:, 1]\n",
    "featureX_sub['ConcatGen5_mean'] = clf.predict_proba(sfm_rf_concat.transform(X_sub_concat))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfm_rf_concat = SelectFromModel(RFC(n_estimators=650,\n",
    "                                    criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL),\n",
    "                               threshold='5*median')\n",
    "sfm_rf_concat.fit(X_train_concat, y_train)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_train_concat,\n",
    "                            y=y_train,\n",
    "                            validData=X_valid_concat,\n",
    "                            testData=X_test_concat,\n",
    "                            preTrans=sfm_rf_concat, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "featureX_train['ConcatGen5_median'] = y_\n",
    "featureX_test['ConcatGen5_median'] = yt_[:, 1]\n",
    "featureX_valid['ConcatGen5_median'] = yv_[:, 1]\n",
    "featureX_sub['ConcatGen5_median'] = clf.predict_proba(sfm_rf_concat.transform(X_sub_concat))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "         axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices])\n",
    "plt.xticks(arange(1, len(indices), 50), X_train_concat.columns[sfm_rf_concat.get_support()][indices])\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разобьем данные по некоторым признакам\n",
    "Были просмотрены все некатегориальные признаки и выбраны, которые показались интересными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "col = 'V103'\n",
    "\n",
    "rnd_seed = 0\n",
    "for col in ['V103', 'V4', 'V8', 'V42', 'V41', 'V91', 'V95', 'V120', 'V115', 'V181']:\n",
    "    print col\n",
    "    X1 = X_train.copy()\n",
    "    X1['y'] = y_train\n",
    "    y1 = X1[X1[col] != 0].y.as_matrix()\n",
    "    X1 = X1[X1[col] != 0].drop('y', axis=1)\n",
    "\n",
    "    X0 = X_train.copy()\n",
    "    X0['y'] = y_train\n",
    "    y0 = X0[X0[col] == 0].y.as_matrix()\n",
    "    X0 = X0[X0[col] == 0].drop('y', axis=1)\n",
    "\n",
    "    X1_valid = X_valid.copy()\n",
    "    X1_valid['y'] = y_valid\n",
    "    y1_valid = X1_valid[X1_valid[col] != 0].y.as_matrix()\n",
    "    X1_valid = X1_valid[X1_valid[col] != 0].drop('y', axis=1)\n",
    "\n",
    "    X0_valid = X_valid.copy()\n",
    "    X0_valid['y'] = y_valid\n",
    "    y0_valid = X0_valid[X0_valid[col] == 0].y.as_matrix()\n",
    "    X0_valid = X0_valid[X0_valid[col] == 0].drop('y', axis=1)\n",
    "\n",
    "    X1_test = X_test.copy()\n",
    "    X1_test['y'] = y_test\n",
    "    y1_test = X1_test[X1_test[col] != 0].y.as_matrix()\n",
    "    X1_test = X1_test[X1_test[col] != 0].drop('y', axis=1)\n",
    "\n",
    "    X0_test = X_test.copy()\n",
    "    X0_test['y'] = y_test\n",
    "    y0_test = X0_test[X0_test[col] == 0].y.as_matrix()\n",
    "    X0_test = X0_test[X0_test[col] == 0].drop('y', axis=1)\n",
    "\n",
    "\n",
    "    X1_sub = X_sub.copy()\n",
    "    X1_sub = X1_sub[X1_sub[col] != 0]\n",
    "    X0_sub = X_sub.copy()\n",
    "    X0_sub = X0_sub[X0_sub[col] == 0]\n",
    "\n",
    "\n",
    "    sfm_rf_concat_1 = SelectFromModel(RFC(n_estimators=500, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "    sfm_rf_concat_1.fit(X1, y1)\n",
    "    y1_, yv1_, yt1_, clf1, sc1_ = getCVModel_fit_transform(\n",
    "                                RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL+rnd_seed),\n",
    "                                X=X1,\n",
    "                                y=y1,\n",
    "                                validData=X1_valid,\n",
    "                                testData=X1_test,\n",
    "                                preTrans=sfm_rf_concat_1, \n",
    "                                nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "    ys1_ = clf1.predict_proba(sfm_rf_concat_1.transform(X1_sub))\n",
    "\n",
    "\n",
    "    sfm_rf_concat_0 = SelectFromModel(RFC(n_estimators=500, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "    sfm_rf_concat_0.fit(X0, y0)\n",
    "    y0_, yv0_, yt0_, clf0, sc0_ = getCVModel_fit_transform(\n",
    "                                RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL+rnd_seed),\n",
    "                                X=X0,\n",
    "                                y=y0,\n",
    "                                validData=X0_valid,\n",
    "                                testData=X0_test,\n",
    "                                preTrans=sfm_rf_concat_0, \n",
    "                                nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "    ys0_ = clf0.predict_proba(sfm_rf_concat_0.transform(X0_sub))\n",
    "\n",
    "    print log_loss(np.append(y0_valid, y1_valid), np.append(yv0_[:,1], yv1_[:,1]))\n",
    "    print log_loss(np.append(y0_test, y1_test), np.append(yt0_[:,1], yt1_[:,1]))\n",
    "\n",
    "\n",
    "    X0_sub['y'] = ys0_[:, 1]\n",
    "    X1_sub['y'] = ys1_[:, 1]\n",
    "    X0_test['y'] = yt0_[:, 1]\n",
    "    X1_test['y'] = yt1_[:, 1]\n",
    "    X0_valid['y'] = yv0_[:, 1]\n",
    "    X1_valid['y'] = yv1_[:, 1]\n",
    "    X0['y'] = y0_\n",
    "    X1['y'] = y1_\n",
    "    \n",
    "    rnd_seed = rnd_seed + 100132\n",
    "\n",
    "\n",
    "    featureX_train['Split' + col] = pd.concat([X0, X1], axis=0)['y']\n",
    "    featureX_sub['Split' + col] = pd.concat([X0_sub, X1_sub], axis=0)['y']\n",
    "    featureX_valid['Split' + col] = pd.concat([X0_valid, X1_valid], axis=0)['y']\n",
    "    featureX_test['Split' + col] = pd.concat([X0_test, X1_test], axis=0)['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputer\n",
    "Baseline решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_imputer = X_train.copy()\n",
    "X_test_imputer = X_test.copy()\n",
    "X_valid_imputer = X_valid.copy()\n",
    "X_sub_imputer = X_sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_imputer.replace(-9999, np.NAN, inplace=True)\n",
    "X_test_imputer.replace(-9999, np.NAN, inplace=True)\n",
    "X_sub_imputer.replace(-9999, np.NAN, inplace=True)\n",
    "X_valid_imputer.replace(-9999, np.NAN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\n",
    "imp.fit(X_train_imputer)\n",
    "\n",
    "X_train_imputer = pd.DataFrame(imp.transform(X_train_imputer), index=X_train_imputer.index)\n",
    "X_test_imputer = pd.DataFrame(imp.transform(X_test_imputer), index=X_test_imputer.index)\n",
    "X_valid_imputer = pd.DataFrame(imp.transform(X_valid_imputer), index=X_valid_imputer.index)\n",
    "X_sub_imputer = pd.DataFrame(imp.transform(X_sub_imputer), index=X_sub_imputer.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_imputer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sfm_rf_imputer = SelectFromModel(RFC(n_estimators=750,\n",
    "                                    criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sfm_rf_imputer.fit(X_train_imputer, y_train)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            ETC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_train_imputer,\n",
    "                            y=y_train,\n",
    "                            validData=X_valid_imputer,\n",
    "                            testData=X_test_imputer,\n",
    "                            preTrans=sfm_rf_imputer, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)\n",
    "\n",
    "\n",
    "print sc_\n",
    "print log_loss(y_valid, yv_)\n",
    "print log_loss(y_test, yt_)\n",
    "\n",
    "featureX_train['ImputerMost'] = y_\n",
    "featureX_test['ImputerMost'] = yt_[:, 1]\n",
    "featureX_valid['ImputerMost'] = yv_[:, 1]\n",
    "featureX_sub['ImputerMost'] = clf.predict_proba(sfm_rf_imputer.transform(X_sub_imputer))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итого\n",
    "Добавляем результаты всех вышеприведенных моделей к начальным данным. Из-за какого-то бага в данные train 'SplitV...' попали NA значения. Разбираться почему так вышло не было времени, поэтому решил выкинуть из обучения.\n",
    "\n",
    "Обучил 4 модели как в самом начале:\n",
    "1. RandomForest 'важные' признаки выбираются RandomForest\n",
    "2. RandomForest 'важные' признаки выбираются ExtraTreesClassifier\n",
    "3. ExtraTreesClassifier 'важные' признаки выбираются RandomForest\n",
    "4. ExtraTreesClassifier 'важные' признаки выбираются ExtraTreesClassifier\n",
    "\n",
    "Выход усредняю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train_ = pd.concat([X_train, featureX_train], axis=1).drop(['SplitV41','SplitV91','SplitV95', 'SplitV120', \n",
    "                                                              'SplitV115', 'SplitV181', 'SplitV103', 'SplitV4',\n",
    "                                                              'SplitV42', 'SplitV8'], axis=1)\n",
    "X_sub_ = pd.concat([X_sub, featureX_sub], axis=1).drop(['SplitV41','SplitV91','SplitV95', 'SplitV120', \n",
    "                                                              'SplitV115', 'SplitV181', 'SplitV103', 'SplitV4',\n",
    "                                                              'SplitV42', 'SplitV8'], axis=1)\n",
    "X_test_ = pd.concat([X_test, featureX_test], axis=1).drop(['SplitV41','SplitV91','SplitV95', 'SplitV120', \n",
    "                                                              'SplitV115', 'SplitV181', 'SplitV103', 'SplitV4',\n",
    "                                                              'SplitV42', 'SplitV8'], axis=1)\n",
    "X_valid_ = pd.concat([X_valid, featureX_valid], axis=1).drop(['SplitV41','SplitV91','SplitV95', 'SplitV120', \n",
    "                                                              'SplitV115', 'SplitV181', 'SplitV103', 'SplitV4',\n",
    "                                                              'SplitV42', 'SplitV8'], axis=1)\n",
    "\n",
    "# RFC-RFC\n",
    "sCount = SelectFromModel(RFC(n_estimators=800, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sCount.fit(X_train_, y_train)\n",
    "rfCount = RFC(n_estimators=25000, criterion='entropy', random_state=GLOBAL_RND_MODEL)\n",
    "rfCount.fit(sCount.transform(X_train_), y_train)\n",
    "\n",
    "print log_loss(y_test, rfCount.predict_proba(sCount.transform(X_test_)))\n",
    "print log_loss(y_valid, rfCount.predict_proba(sCount.transform(X_valid_)))\n",
    "\n",
    "# RFC-ETC\n",
    "sCount1 = SelectFromModel(RFC(n_estimators=800, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sCount1.fit(X_train_, y_train)\n",
    "rfCount1 = ETC(n_estimators=25000, criterion='entropy', random_state=GLOBAL_RND_MODEL)\n",
    "rfCount1.fit(sCount1.transform(X_train_), y_train)\n",
    "\n",
    "print log_loss(y_test, rfCount1.predict_proba(sCount1.transform(X_test_)))\n",
    "print log_loss(y_valid, rfCount1.predict_proba(sCount1.transform(X_valid_)))\n",
    "\n",
    "# ETC-RFC\n",
    "sCount2 = SelectFromModel(ETC(n_estimators=800, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sCount2.fit(X_train_, y_train)\n",
    "rfCount2 = RFC(n_estimators=25000, criterion='entropy', random_state=GLOBAL_RND_MODEL)\n",
    "rfCount2.fit(sCount2.transform(X_train_), y_train)\n",
    "\n",
    "print log_loss(y_test, rfCount2.predict_proba(sCount2.transform(X_test_)))\n",
    "print log_loss(y_valid, rfCount2.predict_proba(sCount2.transform(X_valid_)))\n",
    "\n",
    "# ETC-ETC\n",
    "sCount3 = SelectFromModel(ETC(n_estimators=800, criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sCount3.fit(X_train_, y_train);\n",
    "rfCount3 = ETC(n_estimators=25000, criterion='entropy', random_state=GLOBAL_RND_MODEL)\n",
    "rfCount3.fit(sCount3.transform(X_train_), y_train)\n",
    "\n",
    "print log_loss(y_test, rfCount3.predict_proba(sCount3.transform(X_test_)))\n",
    "print log_loss(y_valid, rfCount3.predict_proba(sCount3.transform(X_valid_)))\n",
    "\n",
    "\n",
    "# MEAN SCORE\n",
    "YTEST_ = rfCount.predict_proba(sCount.transform(X_test_)) + \\\n",
    "               rfCount1.predict_proba(sCount1.transform(X_test_)) + \\\n",
    "               rfCount2.predict_proba(sCount2.transform(X_test_)) + \\\n",
    "               rfCount3.predict_proba(sCount3.transform(X_test_))\n",
    "YTEST_ = YTEST_ / 4\n",
    "print log_loss(y_test, YTEST_)\n",
    "\n",
    "\n",
    "YVALID_ = rfCount.predict_proba(sCount.transform(X_valid_)) + \\\n",
    "               rfCount1.predict_proba(sCount1.transform(X_valid_)) + \\\n",
    "               rfCount2.predict_proba(sCount2.transform(X_valid_)) + \\\n",
    "               rfCount3.predict_proba(sCount3.transform(X_valid_))\n",
    "YVALID_ = YVALID_ / 4           \n",
    "print log_loss(y_valid, YVALID_)\n",
    "\n",
    " \n",
    "YSUBPRED_ = rfCount.predict_proba(sCount.transform(X_sub_)) + \\\n",
    "               rfCount1.predict_proba(sCount1.transform(X_sub_)) + \\\n",
    "               rfCount2.predict_proba(sCount2.transform(X_sub_)) + \\\n",
    "               rfCount3.predict_proba(sCount3.transform(X_sub_))\n",
    "YSUBPRED_ = YSUBPRED_ / 4          \n",
    "\n",
    "dfRES = pd.DataFrame()\n",
    "dfRES['Id'] = np.arange(len(YSUBPRED_))\n",
    "dfRES['Prediction'] = YSUBPRED_[:, 1]\n",
    "\n",
    "# Неожиданно, но получился даже тот же результат\n",
    "dfRES.to_csv('y.predicted_26_all_data_verify.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что еще\n",
    "Проанализировав решение, я понял, что часто ошибаюсь на единицах, и поэтому решил построить модель, которая предсказывала бы на сколько сильно ошибается моя итоговая модель. Т.е. я бы получил YPRED и ERROR_PROBABILITY. Чем больше ERROR_PROBABILITY, тем больше мне надо модифичировать ответ YPRED в противоположную сторону.\n",
    "\n",
    "Приведу код из другого IPython notebooka - код не выполнится, но идея станет немного ясней"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Получаю ошибку\n",
    "Y_TRAIN = featureX_train.ix[:, 0:15].mean(axis=1)\n",
    "YT_ = (Y_TRAIN - y_train)\n",
    "YT_ERROR_ = np.array((YT_ > 0.3) | (YT_ < -.6), dtype=int)\n",
    "\n",
    "Y_TEST = featureX_test.ix[:, 0:15].mean(axis=1)\n",
    "YX_ = (Y_TEST - y_test)\n",
    "YX_ERROR_ = np.array((YX_ > 0.3) | (YX_ < -.6), dtype=int)\n",
    "\n",
    "Y_VALID = featureX_valid.ix[:, 0:15].mean(axis=1)\n",
    "YV_ = (Y_VALID - y_valid)\n",
    "YV_ERROR_ = np.array((YV_ > 0.3) | (YV_ < -.6), dtype=int)\n",
    "\n",
    "X_train_error = pd.concat([X_train, featureX_train.ix[:, 0:15]], axis=1)\n",
    "X_test_error = pd.concat([X_test, featureX_test.ix[:, 0:15]], axis=1)\n",
    "X_valid_error = pd.concat([X_valid, featureX_valid.ix[:, 0:15]], axis=1)\n",
    "X_sub_error = pd.concat([X_sub, featureX_sub.ix[:, 0:15]], axis=1)\n",
    "\n",
    "\n",
    "# Обучаюсь\n",
    "sfm_rf_error = SelectFromModel(RFC(n_estimators=650,\n",
    "                                    criterion='entropy', random_state=GLOBAL_RND_SELECT_MODEL))\n",
    "sfm_rf_error.fit(X_train_error, YT_ERROR_)\n",
    "y_, yv_, yt_, clf, sc_ = getCVModel_fit_transform(\n",
    "                            RFC(n_estimators=2000, criterion='entropy', random_state=GLOBAL_RND_MODEL),\n",
    "                            X=X_train_error,\n",
    "                            y=YT_ERROR_,\n",
    "                            validData=X_valid_error,\n",
    "                            testData=X_test_error,\n",
    "                            preTrans=sfm_rf_error, \n",
    "                            nFolds=GLOBAL_NFOLD, randomState=GLOBAL_RANDOM_CV, needScores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfRES = pd.DataFrame()\n",
    "dfRES['Id'] = np.arange(len(YSUBPRED_))\n",
    "e = (1-error*(error>0.4))\n",
    "yyyy = YSUBPRED_[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а тут модифицирую ответ с помощью подели ошибок. Почему выбранны такие пороговые значения? Во-первых, метод вглядывания. Всматриваясь в графики test, valid, train я выбрал такие значения Во-вторых, все эти пороги надо было програть на Cross Validation и получить оптимальные, но не успел и не верил, что это сработает. А в test и valid была выборка около 200 элементов, которая не предоставила бы адекватный результат. Не хватило, что называется, одного дня :)\n",
    "Эта модель показала результат в public-score 0.23107 против 0.22992 чистого результата без использования error. А на private-score получилось наоборот: подель с модификацией показала 0.21149 против 0.21230."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytyt =  yyyy*(yyyy < 0.4)*(error >= 0.4)*1.3 + yyyy*(yyyy > 0.4)*(error >= 0.4)*.7 + yyyy*(error < 0.4)\n",
    "dfRES['Prediction'] = ytyt#YSUBPRED_[:, 1] * )\n",
    "dfRES.to_csv('y.predicted_29.csv', index = False)\n",
    "plot(dfRES['Prediction'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
